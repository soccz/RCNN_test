{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 깃허브 통해서 다운로드 받는 코드도 이해하면 좋을듯 함...!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 폴더 위치에서 input, working 폴더를 만들어서 읽는 형태\n",
    "DATA_DIR = Path('./input')\n",
    "ROOT_DIR = Path('./working')\n",
    "\n",
    "NUM_CATS = 46\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodellib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualize\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mrcnn/model.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mK\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mKL\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mKE\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mKM\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.engine'"
     ]
    }
   ],
   "source": [
    "# 이 부분에서 str 형태로 로드가 안되는듯함...\n",
    "MASK_RCNN_PATH = str(ROOT_DIR/'Mask_RCNN')\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 깃허브 통해서 직접 다운로드\n",
    "# https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
    "\n",
    "COCO_WEIGHTS_PATH = 'mask_rcnn_coco.h5'\n",
    "#if not os.path.exists(COCO_WEIGHTS_PATH):\n",
    "#    os.system('curl -L -o mask_rcnn_coco.h5 https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5')\n",
    "\n",
    "# 다운로드한 파일 확인\n",
    "#os.system('ls -lh mask_rcnn_coco.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask_RCNN 안의 모델을 살펴보는 것이 중요하겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionConfig(Config):\n",
    "    # 설정이름을 fashion으로 정의\n",
    "    NAME = \"fashion\"\n",
    "    # NUM_CATS = 46 위에서 설정함\n",
    "    NUM_CLASSES = NUM_CATS + 1\n",
    "    \n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 4\n",
    "\n",
    "    # 백본 네트워크 설정\n",
    "    BACKBONE = 'resnet50'\n",
    "\n",
    "    # IMAGE_SIZE = 512 위에서 설정함\n",
    "    IMAGE_MIN_DIM = IMAGE_SIZE\n",
    "    IMAGE_MAX_DIM = IMAGE_SIZE    \n",
    "\n",
    "    # none > 원래 크기를 유지 / square > 지정된 사이즈로 반환 + 빈공간 패딩\n",
    "    # pad64 > 가장 가까운 64 배수로 리사이즈 + 패딩 / crop > 무작위로 자름\n",
    "    IMAGE_RESIZE_MODE = 'none' # 이미지 리사이즈 모드는 입력 이미지를 모델에 맞게 조정하는 방법을 정의\n",
    "\n",
    "    # 앵커 박스의 측면 길이를 설정함(정사각형 형태),  객체를 탐지하는 박스\n",
    "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
    "\n",
    "    # 에폭 당 스텝 수 / 한 에폭 당 배치 학습 수를 설정\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "    # 검증 단계 스텝 수 / 한 에폭 당 배치 검증 수행 수\n",
    "    VALIDATION_STEPS = 200\n",
    "    \n",
    "config = FashionConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 형태 파일 로드\n",
    "with open(DATA_DIR/\"label_descriptions.json\") as f:\n",
    "    label_descriptions = json.load(f)\n",
    "\n",
    "label_names = [x['name'] for x in label_descriptions['categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_df = pd.read_csv(DATA_DIR/\"train.csv\")\n",
    "\n",
    "# 멀티라벨 데이터의 비율을 파악함 / 이미지 안에 클래스가 여러개 있는 경우\n",
    "multilabel_percent = len(segment_df[segment_df['ClassId'].str.contains('_')])/len(segment_df)*100\n",
    "print(f\"Segments that have attributes: {multilabel_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CategoryId 열을 추가함 / ClassId 열에서 기본 클래스만 추출하는 과정\n",
    "segment_df['CategoryId'] = segment_df['ClassId'].str.split('_').str[0]\n",
    "\n",
    "print(\"Total segments: \", len(segment_df))\n",
    "segment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageId 별로 'EncodedPixels', 'CategoryId' 열을 하나의 리스트로 저장\n",
    "image_df = segment_df.groupby('ImageId')[['EncodedPixels', 'CategoryId']].agg(lambda x: list(x))\n",
    "# ImageId 별로 'Height', 'Width' 값의 평균값을 저장\n",
    "size_df = segment_df.groupby('ImageId')[['Height', 'Width']].mean()\n",
    "# image_df, size_df ImageId 기준으로 병합\n",
    "image_df = image_df.join(size_df, on='ImageId')\n",
    "\n",
    "# 동일한 이미지에 대한 세그먼트 정보 (하나의 사진 안에 있는 여러 이미지 정보)를 하나의 데이터 프레임에 통합함\n",
    "# 하나의 이미지 안에 들어있는 여러 세그먼트 정보를 동일한 데이터 프레임 안에 두어 접근 용이성을 높임\n",
    "print(\"Total images: \", len(image_df))\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 읽기 / 색상 변환 / 이미지 리사이즈 > 모델에 적합한 형태로 변환\n",
    "def resize_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)  \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 마스크 생성 > 세그먼트 정보 읽기 > 세그먼트 그리기 > 리사이즈 > 최종 마스크 생성\n",
    "\n",
    "class FashionDataset(utils.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        # label_names 리스트를 데이터셋에 추가\n",
    "        for i, name in enumerate(label_names):\n",
    "            self.add_class(\"fashion\", i+1, name)\n",
    "        \n",
    "        #  add_image 메서드 통해 이미지 정보를 데이터셋에 추가\n",
    "        for i, row in df.iterrows():\n",
    "            self.add_image(\"fashion\", \n",
    "                           image_id=row.name, \n",
    "                           path=str(DATA_DIR/'train'/row.name), \n",
    "                           labels=row['CategoryId'],\n",
    "                           annotations=row['EncodedPixels'], \n",
    "                           height=row['Height'], width=row['Width'])\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path'], [label_names[int(x)] for x in info['labels']]\n",
    "    \n",
    "    def load_image(self, image_id):\n",
    "        return resize_image(self.image_info[image_id]['path'])\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "\n",
    "        height = int(info['height'])\n",
    "        width = int(info['width'])\n",
    "\n",
    "        # mask 배열 초기화 + labels 리스트 초기화\n",
    "        mask = np.zeros((IMAGE_SIZE, IMAGE_SIZE, len(info['annotations'])), dtype=np.uint8)\n",
    "        labels = []\n",
    "\n",
    "        # annotation 안에는 압축이나 픽셀화 된 숫자 형태의 이미지는 아닌 이미지 정보가 들어있고 \n",
    "        # 그걸 for문을 통해 이미지 형태로 만드는 것\n",
    "        # annotation, label 를 통해 세그먼트의 마스크를 생성함\n",
    "        for m, (annotation, label) in enumerate(zip(info['annotations'], info['labels'])):\n",
    "            sub_mask = np.full(height * width, 0, dtype=np.uint8)\n",
    "            annotation = [int(x) for x in annotation.split(' ')]\n",
    "\n",
    "            # sub_mask 배열을 재구성하고 리사이즈함 / 이미지 압축함\n",
    "            # annotation[::2] RLE 인코딩의 시작 위치를 가져온다\n",
    "            # 압축된 형태로 저장된 세그먼트 정보를 실제 이미지 형태로 복원할 수 있음\n",
    "            for i, start_pixel in enumerate(annotation[::2]):\n",
    "                # 1로 칠해라\n",
    "                sub_mask[start_pixel: start_pixel+annotation[2*i+1]] = 1\n",
    "\n",
    "            sub_mask = sub_mask.reshape((height, width), order='F')\n",
    "            sub_mask = cv2.resize(sub_mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            mask[:, :, m] = sub_mask\n",
    "            labels.append(int(label)+1)\n",
    "            \n",
    "        return mask, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FashionDataset(image_df)\n",
    "dataset.prepare()\n",
    "\n",
    "for i in range(6):\n",
    "    image_id = random.choice(dataset.image_ids)\n",
    "    print(dataset.image_reference(image_id))\n",
    "    \n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names, limit=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터를 5개로 나누고 / 첫 번째 폴드 선택\n",
    "FOLD = 0\n",
    "N_FOLDS = 5\n",
    "\n",
    "# 데이터 무작위로 섞고 5개로 나눔\n",
    "kf = KFold(n_splits=N_FOLDS, random_state=42, shuffle=True)\n",
    "splits = kf.split(image_df)\n",
    "\n",
    "def get_fold():    \n",
    "    for i, (train_index, valid_index) in enumerate(splits):\n",
    "        if i == FOLD:\n",
    "            return image_df.iloc[train_index], image_df.iloc[valid_index]\n",
    "        \n",
    "train_df, valid_df = get_fold()\n",
    "\n",
    "train_dataset = FashionDataset(train_df)\n",
    "train_dataset.prepare()\n",
    "\n",
    "valid_dataset = FashionDataset(valid_df)\n",
    "valid_dataset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 검증 데이터에서 각 카테고리의 분포를 시각화하고, 전체 이미지와 세그먼트의 개수를 출력함\n",
    "\n",
    "# np.concatenate 배열 합치기 / train_df['CategoryId'].values > CategoryId 모든 값 배열화\n",
    "train_segments = np.concatenate(train_df['CategoryId'].values).astype(int)\n",
    "print(\"Total train images: \", len(train_df))\n",
    "print(\"Total train segments: \", len(train_segments))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "# np.unique > 배열의 고유한 값\n",
    "values, counts = np.unique(train_segments, return_counts=True)\n",
    "plt.bar(values, counts)\n",
    "plt.xticks(values, label_names, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "valid_segments = np.concatenate(valid_df['CategoryId'].values).astype(int)\n",
    "print(\"Total train images: \", len(valid_df))\n",
    "print(\"Total validation segments: \", len(valid_segments))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "values, counts = np.unique(valid_segments, return_counts=True)\n",
    "plt.bar(values, counts)\n",
    "plt.xticks(values, label_names, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 업데이트 비율? 속도?\n",
    "LR = 1e-4\n",
    "# 전체 훈련 데이터 학습하는 반복 횟수\n",
    "EPOCHS = [2, 6, 8]\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-CNN 모델 생성 / 모델을 훈련 모드로 설정\n",
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n",
    "\n",
    "# 가충치 로드 / exclude > 특정 레이어 제외 후 가중치 로드\n",
    "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
    "    'mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgaug 라이브러리 (iaa) / iaa.Sequential > 지정된 순서대로 증강 기법을 적용함\n",
    "# iaa.Fliplr(0.5) > 이미지 좌우 반전 / 0.5 > 50%\n",
    "# 다양한 데이터 학습할 수 있도록 도움\n",
    "\n",
    "augmentation = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time > 실행 시간 측정 / epochs=EPOCHS[0] > 위에서 설정한 배열 중 첫번째\n",
    "# 모델의 헤드 레이어만 훈련하고 데이터 증강은 사용하지 않음\n",
    "\n",
    "%%time\n",
    "model.train(train_dataset, valid_dataset,\n",
    "            learning_rate=LR*2,\n",
    "            epochs=EPOCHS[0],\n",
    "            layers='heads',\n",
    "            augmentation=None)\n",
    "\n",
    "history = model.keras_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 모든 레이어 훈련함 / 데이터 증강 사용\n",
    "\n",
    "%%time\n",
    "model.train(train_dataset, valid_dataset,\n",
    "            learning_rate=LR,\n",
    "            epochs=EPOCHS[1],\n",
    "            layers='all',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "# for문을 통해 훈련 기록 누적\n",
    "new_history = model.keras_model.history.history\n",
    "for k in new_history: history[k] = history[k] + new_history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률을 다르게 설정하는 이유 > 학습률은 모델이 가중치를 업데이트하는 속도를 결정함, 최적의 학습 속도와 안정성을 찾음\n",
    "# 에폭 수 > 전체 데이터 셋 반복 수를 결정함 점점 많은 에폭 수를 두어 세밀하게 학습, 과적합 방지\n",
    "# layers > 새로운 데이터셋에 맞추기 위해 heads만 / all의 경우 전체를 세밀하게 조정\n",
    "\n",
    "# 초반에는 학습률을 크게 두고 적은 에폭 수로 빠르게 학습하고\n",
    "# 뒤로 갈 수록 학습률을 촘촘하게 두고 많은 에폭 수로 세밀하고 최적의 학습을 찾는다\n",
    "\n",
    "%%time\n",
    "model.train(train_dataset, valid_dataset,\n",
    "            learning_rate=LR/5, # 5분의 1로 낮춤\n",
    "            epochs=EPOCHS[2],\n",
    "            layers='all',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "# 병합 과정\n",
    "new_history = model.keras_model.history.history\n",
    "for k in new_history: history[k] = history[k] + new_history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트의 마지막 값을 기준으로 에포크 범위를 설정\n",
    "epochs = range(EPOCHS[-1])\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# 숫자는 행,열,위치 순서로 의미가 있음 > 131\n",
    "plt.subplot(131)\n",
    "# x축, y축, 선 이름\n",
    "plt.plot(epochs, history['loss'], label=\"train loss\")\n",
    "plt.plot(epochs, history['val_loss'], label=\"valid loss\")\n",
    "plt.legend() # 범례 추가\n",
    "plt.subplot(132)\n",
    "plt.plot(epochs, history['mrcnn_class_loss'], label=\"train class loss\")\n",
    "plt.plot(epochs, history['val_mrcnn_class_loss'], label=\"valid class loss\")\n",
    "plt.legend()\n",
    "plt.subplot(133)\n",
    "plt.plot(epochs, history['mrcnn_mask_loss'], label=\"train mask loss\")\n",
    "plt.plot(epochs, history['val_mrcnn_mask_loss'], label=\"valid mask loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history[\"val_loss\"] 배열에서 가장 작은 값을 가진 인덱스 찾음 > argmin 기능 / 에폭 수 값을 알기 위해 +1 해줌\n",
    "best_epoch = np.argmin(history[\"val_loss\"]) + 1\n",
    "print(\"Best epoch: \", best_epoch)\n",
    "# 위에서 에폭 수를 구하기 위해 +1을 했기에 index 값을 찾기 위한 -1을 해줌\n",
    "print(\"Valid loss: \", history[\"val_loss\"][best_epoch-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기 코드는 수정해야 함 위쪽에서부터 읽지 못해서 그대로 뒀음\n",
    "glob_list = glob.glob(f'/kaggle/working/fashion*/mask_rcnn_fashion_{best_epoch:04d}.h5')\n",
    "model_path = glob_list[0] if glob_list else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 가중치 로드\n",
    "class InferenceConfig(FashionConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "# 추론 설정 적용\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# 모델을 추론 모드로 설정함 > inference / model_dir > 저장할 공간\n",
    "model = modellib.MaskRCNN(mode='inference', # training 모드도 있음\n",
    "                          config=inference_config,\n",
    "                          model_dir=ROOT_DIR)\n",
    "\n",
    "# model_path 가 비어 있지 않은지 확인\n",
    "assert model_path != '', \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "# 사전 학습된 가중치 로드\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 설명한 RLE 방식을 사용하여 데이터 압축\n",
    "# 0과 1로 이루어진 리스트\n",
    "def to_rle(bits):\n",
    "    rle = [] # 저장할 리스트\n",
    "    pos = 0 # bits 리스트에서 현재 처리 중인 위치를 나타냄\n",
    "    # itertools.groupby를 통해 연속적인 동일 값을 그룹화 한다 + 값이 바뀔 때마다 새로운 그룹을 시작 함수 자체에서 처리\n",
    "    # 그룹화 된 값을 bit는 그룹의 값, group은 그룹에 속한 값을 저장\n",
    "    for bit, group in itertools.groupby(bits):\n",
    "        group_list = list(group) # group 값을 리스트로 변환\n",
    "        if bit: # 1일 경우\n",
    "            rle.extend([pos, sum(group_list)]) # pos를 통해 얻은 현재 위치와 그룹의 길이를 rle에 추가\n",
    "        pos += len(group_list)\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예시\n",
    "\n",
    "bits = [1, 1, 0, 0, 1, 0]\n",
    "for bit, group in itertools.groupby(bits):\n",
    "    print(bit, list(group))\n",
    "\n",
    "출력\n",
    "1 [1, 1]\n",
    "0 [0, 0]\n",
    "1 [1]\n",
    "0 [0]\n",
    "\n",
    "itertools에 대해\n",
    "\n",
    "groupby(iterable, key=None):\n",
    "연속된 동일한 값을 그룹으로 묶습니다. 예를 들어, [1, 1, 0, 0, 1, 0]을 그룹화하여 [1, 1], [0, 0], [1], [0]로 나눕니다.\n",
    "\n",
    "count(start=0, step=1):\n",
    "start부터 step만큼 증가하는 무한 반복자를 생성합니다.\n",
    "\n",
    "cycle(iterable):\n",
    "주어진 반복 가능한 객체를 무한히 반복합니다.\n",
    "\n",
    "repeat(object, times=None):\n",
    "주어진 객체를 times 횟수만큼 반복합니다. times가 지정되지 않으면 무한히 반복합니다.\n",
    "\n",
    "chain(*iterables):\n",
    "여러 반복 가능한 객체들을 순차적으로 연결하여 하나의 반복자로 만듭니다.\n",
    "\n",
    "islice(iterable, start, stop, step):\n",
    "지정된 범위의 요소들을 슬라이스하여 반환합니다.\n",
    "\n",
    "combinations(iterable, r):\n",
    "주어진 반복 가능한 객체에서 길이 r인 모든 조합을 생성합니다.\n",
    "\n",
    "permutations(iterable, r=None):\n",
    "주어진 반복 가능한 객체에서 길이 r인 모든 순열을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마스크가 겹치지 않고 정리, 경계를 계산하여 정확도 향상\n",
    "# masks는 3차원 배열로, 형태는 [height, width, num_masks]\n",
    "\n",
    "def refine_masks(masks, rois):\n",
    "    # masks.reshape(-1, masks.shape[-1]) > [height * width, num_masks] 형태로 배열 변환\n",
    "    # reshape 배열의 형태 변경 함수 -1 로 자동으로 적절한 크기 결정\n",
    "    areas = np.sum(masks.reshape(-1, masks.shape[-1]), axis=0)\n",
    "    # 쉽게 설명하면 배열을 오름차순으로 정리하고 기존 인덱스 값을 출력함\n",
    "    mask_index = np.argsort(areas) # 정렬을 인덱스 값으로 함 / 배열을 오름차순으로 정렬했을 때의 인덱스를 반환\n",
    "\n",
    "    # masks.shape은 (height, width, num_masks) 형태의 튜플을 반환 -1을 통해 height, widet 형태의 배열\n",
    "    union_mask = np.zeros(masks.shape[:-1], dtype=bool) # 빈 마스크 초기화\n",
    "\n",
    "    # 작은 면적의 마스크부터 순서대로 겹치는 부분을 제거\n",
    "    for m in mask_index:\n",
    "        # union_mask에 not을 취하고 m번째 마스크와 AND 연산 > 겹치지 않는 부분만 남김\n",
    "        masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))\n",
    "        # union_mask 현재까지 합쳐진 마스크와 m번 째 마스크 OR 연산\n",
    "        union_mask = np.logical_or(masks[:, :, m], union_mask)\n",
    "\n",
    "    # ROI 업데이트\n",
    "    for m in range(masks.shape[-1]):\n",
    "        # m번째가 True면 행,열 반환\n",
    "        mask_pos = np.where(masks[:, :, m]==True)\n",
    "\n",
    "        # 마스크의 경계 부분을 파악하고 객체의 위치와 크기를 파악할 수 있음 > min, max를 통해\n",
    "        if np.any(mask_pos): # True인 경우에만 확인\n",
    "            # 경계에 대한 부분을 나타내는 좌표\n",
    "            y1, x1 = np.min(mask_pos, axis=1)\n",
    "            y2, x2 = np.max(mask_pos, axis=1)\n",
    "            rois[m, :] = [y1, x1, y2, x2]\n",
    "    return masks, rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sub_list = [] # 예측 결과 저장\n",
    "missing_count = 0 # 마스크가 없는 이미지 카운트\n",
    "\n",
    "# tqdm > 실시간 확인 가능 / iterrows 를 통해 데이터 프레임 행을 하나씩 반복하여 처리\n",
    "# sample_df.iterrows() > 데이터 프레임의 각 행을 순차적으로 반환\n",
    "for i, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    # 이미지 로드하고 리사이즈\n",
    "    image = resize_image(str(DATA_DIR/'test'/row['ImageId']))\n",
    "    # 리사이즈 된 이미지를 모델에 입력 / model.detect 함수로 예측 결과 반환\n",
    "    # detect를 통해 여러 이미지를 처리할 수 있고 리스트 형태로 반환된다\n",
    "    # [image]에서 단일 이미지에 대한 예측 결과 리스트\n",
    "    result = model.detect([image])[0\n",
    "\n",
    "    # 마스크가 있는 경우 처리\n",
    "    if result['masks'].size > 0:\n",
    "        # 객체들의 마스크, 객체들의 경계 / _ 는 일반적으로 중요하지 않아서 무시할 때 사용\n",
    "        # masks, rois 2가지 값을 반환 받는데 코드에서 rois 사용하지 않음\n",
    "        masks, _ = refine_masks(result['masks'], result['rois'])\n",
    "        for m in range(masks.shape[-1]): # 마스크의 개수\n",
    "            # mask는 3차원 배열(h,w,m) 모든행, 모든열, m번째 마스크\n",
    "            # ravel 1차원으로 펼치는 함수 / F > 열 우선 순서로 배열\n",
    "            mask = masks[:, :, m].ravel(order='F')\n",
    "            rle = to_rle(mask)  # to_rle 함수\n",
    "            label = result['class_ids'][m] - 1\n",
    "            # 현재 이미지의 아이디, RLE 리스트를 문자열로 반환, 아래 예시 찾모\n",
    "            sub_list.append([row['ImageId'], ' '.join(list(map(str, rle))), label])\n",
    "    else:\n",
    "        # 마스크가 없으면 RLE 기본 값 '1 1', 기본 클래스 ID 23\n",
    "        sub_list.append([row['ImageId'], '1 1', 23])\n",
    "        missing_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예시\n",
    "\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "sample_df = pd.DataFrame(data)\n",
    "\n",
    "### iterrows와 tqdm 사용 예시\n",
    "for i, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    print(i, row)\n",
    "\n",
    "0 A    1\n",
    "  B    4\n",
    "Name: 0, dtype: int64\n",
    "1 A    2\n",
    "  B    5\n",
    "Name: 1, dtype: int64\n",
    "2 A    3\n",
    "  B    6\n",
    "Name: 2, dtype: int64\n",
    "\n",
    "\n",
    "### ' '.join(list(map(str, rle)))\n",
    "to_rle(mask)는 마스크를 RLE (Run-Length Encoding) 형태로 변환합니다.\n",
    "예를 들어, [1, 1, 0, 0, 1, 0]은 [1 2, 5 1]로 변환됩니다.\n",
    "\n",
    "map(str, rle)는 map 함수를 통해 RLE 리스트의 각 요소를 순서대로 가져와 str을 통해 문자열로 변환합니다.\n",
    "rle 리스트의 각 숫자 요소를 문자열로 변환합니다.\n",
    "\n",
    "list(map(str, rle))는 문자열 리스트를 만듭니다.\n",
    "예를 들어, ['1', '2', '5', '1']로 변환됩니다.\n",
    "\n",
    "' '.join(list(map(str, rle)))는 이 문자열 리스트를 하나의 문자열로 결합합니다.\n",
    "' '.join(['1', '2', '5', '1'])는 \"1 2 5 1\"로 변환됩니다.\n",
    "이렇게 하는 이유는 최종적으로 제출할 때 문자열 형태의 RLE가 필요하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 데이터 프레임으로 변환 / sample_df.columns.values > 열 설정\n",
    "submission_df = pd.DataFrame(sub_list, columns=sample_df.columns.values)\n",
    "print(\"Total image results: \", submission_df['ImageId'].nunique())\n",
    "print(\"Missing Images: \", missing_count) # 마스크가 없는 이미지 수\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    # 무작위 하나의 이미지 ID\n",
    "    image_id = sample_df.sample()['ImageId'].values[0]\n",
    "    image_path = str(DATA_DIR/'test'/image_id)\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    result = model.detect([resize_image(image_path)])\n",
    "    r = result[0]\n",
    "    \n",
    "    if r['masks'].size > 0:\n",
    "        masks = np.zeros((img.shape[0], img.shape[1], r['masks'].shape[-1]), dtype=np.uint8)\n",
    "        for m in range(r['masks'].shape[-1]):\n",
    "            masks[:, :, m] = cv2.resize(r['masks'][:, :, m].astype('uint8'), \n",
    "                                        (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        y_scale = img.shape[0]/IMAGE_SIZE\n",
    "        x_scale = img.shape[1]/IMAGE_SIZE\n",
    "        rois = (r['rois'] * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n",
    "        \n",
    "        masks, rois = refine_masks(masks, rois)\n",
    "    else:\n",
    "        masks, rois = r['masks'], r['rois']\n",
    "        \n",
    "    visualize.display_instances(img, rois, masks, r['class_ids'], \n",
    "                                ['bg']+label_names, r['scores'],\n",
    "                                title=image_id, figsize=(12, 12))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 862545,
     "sourceId": 13032,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 25160,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
